{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "659c85b8-eb74-44f7-a709-3494fec734e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5521d44-e02b-4bbc-9382-4bc3842e7a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available and set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73290e39-1a8b-4783-8822-256838d423f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your DataFrame\n",
    "# Replace 'your_dataframe.csv' with the actual filename or method to load your data\n",
    "df = pd.read_csv('Desktop/ML_Final_Project/train_dataframe.csv')\n",
    "test_df = pd.read_csv('Desktop/ML_Final_Project/test_dataframe.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e252a52-9ce0-45c6-9912-94f40fa2de9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24555, 1, 23])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming `df` is your training DataFrame and `test_df` is your testing DataFrame\n",
    "X = df.drop('label', axis=1).values\n",
    "y = df['label'].values\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Determine the number of classes and input shape\n",
    "num_classes = len(set(y_encoded))\n",
    "input_shape = X.shape[1]\n",
    "\n",
    "# Split data into training and testing sets for training dataset\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_tensor = torch.Tensor(X_train).unsqueeze(1)  # shape: [batch_size, 1, sequence_length]\n",
    "y_train_tensor = torch.Tensor(y_train).long()\n",
    "X_val_tensor = torch.Tensor(X_val).unsqueeze(1)  # shape: [batch_size, 1, sequence_length]\n",
    "y_val_tensor = torch.Tensor(y_val).long()\n",
    "\n",
    "# Create dataset and dataloader for training\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "X_train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4ecd113-757d-4b4b-a6f8-d4ea75715a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNetAudio(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes):\n",
    "        super(ResNetAudio, self).__init__()\n",
    "        self.in_channels = 16\n",
    "        self.conv = nn.Conv1d(1, 16, kernel_size=7, stride=1, padding=3)\n",
    "        self.bn = nn.BatchNorm1d(16)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self._make_layer(block, 16, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 32, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 64, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 128, layers[3], stride=2)  # Additional layer\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(128, num_classes)  # Adjust the input size of the fully connected layer\n",
    "\n",
    "    def _make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_channels != out_channels:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv1d(self.in_channels, out_channels, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm1d(out_channels),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        self.in_channels = out_channels\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(out_channels, out_channels))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)  # Additional layer\n",
    "        x = self.avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "638f287c-5267-4572-9a1e-92a43c7f8f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2317c526-86bb-4048-a334-483b7cbb3006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.06479443612445325, Train Accuracy: 15.634290368560375%, Val Accuracy: 12.054080469131781%\n",
      "Epoch 21, Loss: 0.024037818104860085, Train Accuracy: 62.59824882915903%, Val Accuracy: 52.712168105554646%\n",
      "Epoch 41, Loss: 0.008926553282802544, Train Accuracy: 84.93585827733659%, Val Accuracy: 70.89102459683988%\n",
      "Epoch 61, Loss: 0.00761564723560194, Train Accuracy: 88.67440439828955%, Val Accuracy: 72.2430363251344%\n",
      "Epoch 81, Loss: 0.0037347754620765078, Train Accuracy: 94.0541641213602%, Val Accuracy: 72.03127545202803%\n",
      "Epoch 101, Loss: 0.002053536510138997, Train Accuracy: 96.48951333740582%, Val Accuracy: 71.15165336374002%\n",
      "Epoch 121, Loss: 0.0017154984504473344, Train Accuracy: 97.39767868051314%, Val Accuracy: 75.37058152793614%\n",
      "Epoch 141, Loss: 0.0014419075189073646, Train Accuracy: 97.8415801262472%, Val Accuracy: 72.68284736927838%\n",
      "Epoch 161, Loss: 0.0014916237758879245, Train Accuracy: 97.55650580329872%, Val Accuracy: 65.33637400228051%\n",
      "Epoch 181, Loss: 0.0008496173004391925, Train Accuracy: 98.5176135206679%, Val Accuracy: 77.48819025899984%\n",
      "Epoch 201, Loss: 0.001687874199321516, Train Accuracy: 97.80900020362452%, Val Accuracy: 74.78416680241081%\n",
      "Epoch 221, Loss: 0.0010316565371205674, Train Accuracy: 98.415801262472%, Val Accuracy: 75.33800293207362%\n",
      "Epoch 241, Loss: 0.0007870848289816264, Train Accuracy: 98.82712278558338%, Val Accuracy: 78.48183743280664%\n",
      "Epoch 261, Loss: 0.0008710853816887855, Train Accuracy: 98.7253105273875%, Val Accuracy: 78.92164847695065%\n",
      "Epoch 281, Loss: 0.0006892435872838521, Train Accuracy: 98.93708002443495%, Val Accuracy: 76.51083238312428%\n"
     ]
    }
   ],
   "source": [
    "num_classes = num_classes  # Adjust as per your dataset\n",
    "hidden_size = 128  # LSTM hidden size\n",
    "num_layers = 2  # Number of LSTM layers\n",
    "model = ResNetAudio(ResidualBlock, [2, 2, 2, 2], num_classes=num_classes) \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 300\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train_predictions = 0\n",
    "    total_train_predictions = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate training loss and accuracy\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_train_predictions += (predicted == labels).sum().item()\n",
    "        total_train_predictions += labels.size(0)\n",
    "\n",
    "    train_accuracy = correct_train_predictions / total_train_predictions * 100\n",
    "\n",
    "    # Validation accuracy\n",
    "    if epoch % 20 == 0:\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        correct_val_predictions = 0\n",
    "        total_val_predictions = 0\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(X_val_tensor)\n",
    "            _, predicted = torch.max(val_outputs, 1)\n",
    "            correct_val_predictions += (predicted == y_val_tensor).sum().item()\n",
    "            total_val_predictions += y_val_tensor.size(0)\n",
    "\n",
    "        test_accuracy = correct_val_predictions / total_val_predictions * 100\n",
    "        model.train()  # Set the model back to training mode\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {running_loss / total_train_predictions}, Train Accuracy: {train_accuracy}%, Val Accuracy: {test_accuracy}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91e6fc4e-9cd1-4fb9-baa4-cc1b17e13935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    eighties       0.83      1.00      0.91         5\n",
      "     fifties       0.86      0.80      0.83       205\n",
      "    fourties       0.74      0.80      0.77       236\n",
      "   seventies       0.71      0.83      0.77        36\n",
      "     sixties       0.90      0.86      0.88        88\n",
      "       teens       0.71      0.73      0.72       117\n",
      "    thirties       0.76      0.77      0.76       389\n",
      "    twenties       0.81      0.79      0.80       466\n",
      "\n",
      "    accuracy                           0.79      1542\n",
      "   macro avg       0.79      0.82      0.81      1542\n",
      "weighted avg       0.79      0.79      0.79      1542\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "# Prepare the test dataset\n",
    "X_test = test_df.drop('label', axis=1).values\n",
    "y_test = test_df['label'].values\n",
    "y_test_encoded = label_encoder.transform(y_test)  # Use the same encoder as before\n",
    "\n",
    "# Convert test data to PyTorch tensors\n",
    "X_test_tensor = torch.Tensor(X_test).unsqueeze(1)  # shape: [batch_size, 1, sequence_length]\n",
    "y_test_tensor = torch.Tensor(y_test_encoded).long()\n",
    "\n",
    "# Evaluate the model on test dataset\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_tensor)\n",
    "    _, predicted = torch.max(test_outputs, 1)\n",
    "    predicted = predicted.numpy()\n",
    "    y_test_encoded = y_test_encoded.astype(int)\n",
    "\n",
    "# Generate a classification report\n",
    "report = classification_report(y_test_encoded, predicted, target_names=label_encoder.classes_)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92832613-de8c-4dbd-84ba-279c9c11ecde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
